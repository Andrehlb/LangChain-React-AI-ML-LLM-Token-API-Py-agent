{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "pkg_path = os.path.abspath(\"../\")\n",
    "if pkg_path not in sys.path:\n",
    "    sys.path.append(pkg_path)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do agente\n",
    "\n",
    "\n",
    "Criação do agente especialista em filmes como checkpoints salvos na memória de trabalho (`MemorySaver`).\n",
    "\n",
    "A orquestração das ações se baseia no modelo `gpt-4o` da OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from src.agent import ReactAgent\n",
    "\n",
    "llm_agent = AzureChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "agent = ReactAgent(llm=llm_agent, memory=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protótipo de interface - Gradio\n",
    "\n",
    "[Gradio](https://www.gradio.app) é um pacote Python de código aberto que permite a criação de aplicativos web para modelos de machine learning, API ou função Python. Além disso, é pssível compartilhar a aplicação criada por meio de um link público."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front end web app for the assistant\n",
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"Clear\")\n",
    "    chat_history = []\n",
    "    \n",
    "    def user(user_message, history):\n",
    "        answer = agent.answer_question(question=user_message,  thread_id=\"1\")\n",
    "        history.append((user_message, answer[\"response\"]))\n",
    "       \n",
    "        return gr.update(value=\"\"), history\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False)\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requsição assíncrona à API em FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "async def make_request(query: str, session_id: str):\n",
    "    url = 'http://localhost:8000/pushseer'\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'session_id': session_id\n",
    "    }\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'x-api-key': os.getenv('ASSISTANT_API_KEY')\n",
    "    }\n",
    "    \n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url, params=params, headers=headers)\n",
    "        return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = await make_request(query=\"Atores de Matrix\", session_id=\"1\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "click-alert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
